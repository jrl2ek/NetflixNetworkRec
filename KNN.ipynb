{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import utility as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Netflix_Ratings(object):\n",
    "    \n",
    "    def __init__(self,ratings_dir,film_title_csv):\n",
    "        import pandas as pd\n",
    "        import networkx as nx\n",
    "        self.ratings_dir = ratings_dir\n",
    "        self.film_title_csv = film_title_csv\n",
    "        \n",
    "        NetflixTitle = pd.read_excel(self.film_title_csv)\n",
    "        NetflixTitle['Name2'] = NetflixTitle['Name2'].fillna('')\n",
    "        NetflixTitle['Name3'] = NetflixTitle['Name3'].fillna('')\n",
    "        NetflixTitle['Unnamed: 5'] = NetflixTitle['Unnamed: 5'].fillna('')\n",
    "        NetflixTitle['Name'] = NetflixTitle.apply(self.combine, axis=1)\n",
    "        self.names_df = NetflixTitle\n",
    "        \n",
    "        self.ID_to_name, self.name_to_ID = self.create_mappings(self.names_df)\n",
    "        \n",
    "    def combine(self,row):\n",
    "        if row['Name2'] != '':\n",
    "            row['Name'] = str(row['Name']) + ', ' + str(row['Name2'])\n",
    "        if row['Name3'] != '':\n",
    "            row['Name'] = row['Name'] + ', ' + str(row['Name3'])\n",
    "        if row['Unnamed: 5'] != '':\n",
    "            row['Unnamed: 5'] = row['Name'] + ', ' + str(row['Unnamed: 5'])\n",
    "        return row['Name']\n",
    "    \n",
    "    def create_mappings(self,names_df):\n",
    "        IDs = list(names_df['ID'])\n",
    "        names = list(names_df['Name'].str.lower())\n",
    "        ID_to_name = dict(zip(IDs,names))\n",
    "        name_to_ID = dict(zip(names,IDs))\n",
    "        return ID_to_name, name_to_ID\n",
    "    \n",
    "    def create_utility_matrix(self,G):\n",
    "        '''\n",
    "        Given a network G, this method will construct the utility matrix for the movies present in \n",
    "        the nodeset of G that are also within the ratings listed here.\n",
    "        '''\n",
    "        import csv\n",
    "        import numpy as np\n",
    "        import scipy.sparse as ss\n",
    "        \n",
    "        titles_in_matrix = [i for i in G.nodes()]\n",
    "        ids_in_matrix = [self.name_to_ID[x] for x in titles_in_matrix]\n",
    "        \n",
    "        # Loop through the files for each movie, compile the ratings for each movie, and \n",
    "        # get all of the users who rated each movie. \n",
    "        ratings_dict = {}\n",
    "        users = []\n",
    "        for title in titles_in_matrix[:]: #REMOVE THROTTLE\n",
    "            # Get the Netflix id of this movie, and the title of the review file.\n",
    "            filename = f\"{self.ratings_dir}mv_{self.name_to_ID[title]:07}.txt\"\n",
    "            # Build a nested dictionary, where the outer key is the title of the movie,\n",
    "            # the inner key is the numeric identifier of the user, and the value is the\n",
    "            # rating.\n",
    "            ratings = {}\n",
    "            with open(filename,'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                for i,row in enumerate(reader):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        users.append(row[0])\n",
    "                        ratings[row[0]] = row[1]\n",
    "            ratings_dict[title] = ratings\n",
    "        users = list(set(users))\n",
    "        \n",
    "        # Make mappings for the movie title and user to index\n",
    "        title_to_index = dict(zip(titles_in_matrix,range(len(titles_in_matrix))))\n",
    "        index_to_title = dict(zip(range(len(titles_in_matrix)),titles_in_matrix))\n",
    "        user_to_index = dict(zip(users,range(len(users))))\n",
    "        index_to_user = dict(zip(range(len(users)),users))\n",
    "\n",
    "        # Build the utility matrix. [j,i] where j is user and i is movie.\n",
    "        um = np.full((len(users),len(titles_in_matrix)),0)\n",
    "        um = ss.lil_matrix(um)\n",
    "        for title in ratings_dict:\n",
    "            i = title_to_index[title]\n",
    "            for user in ratings_dict[title]:\n",
    "                j = user_to_index[user]\n",
    "                um[j,i] = ratings_dict[title][user]\n",
    "        um = ss.csr_matrix(um)\n",
    "        \n",
    "        self.um = um\n",
    "        self.index_to_title = index_to_title\n",
    "        self.index_to_user = index_to_user\n",
    "        self.title_to_index = title_to_index\n",
    "        self.user_to_index = user_to_index\n",
    "\n",
    "G = util.parse_nodes_edge_file('AllActorG.net')\n",
    "ratings = Netflix_Ratings('training_set/','Netflix-Dataset/movie_titles_test.xls')\n",
    "ratings.create_utility_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( ratings, open( \"saveratings.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTest = pickle.load( open( \"saveratings.p\", \"rb\" ) )\n",
    "ratings = ratingsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratingsTest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-06951ebecc5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mratingsTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ratingsTest' is not defined"
     ]
    }
   ],
   "source": [
    "ratingsTest.um.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_utility_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_Recommender(object):\n",
    "    \n",
    "    def __init__(self,G,ratings,test_size=0.2):\n",
    "        self.G = G # graph\n",
    "        self.ratings = ratings # ratings object\n",
    "        self.U = self.ratings.um\n",
    "        self.test_size = test_size\n",
    "        \n",
    "    def train_test_split(self,user_i,):\n",
    "        \"\"\"\n",
    "        Given a user-vector at index user_i, will return with test_size percent as 0s.\n",
    "        Will also return the indices of the test.\n",
    "        \n",
    "        Returns:\n",
    "            - j,i,v for the sparse vector being tested, after replaced with testing points of 0 rating\n",
    "            - list of tuples that contain the indicies (j,i) of the test elements from self.U\n",
    "        \"\"\"\n",
    "        import scipy.sparse as ss\n",
    "        import numpy as np\n",
    "        \n",
    "        test_size=self.test_size\n",
    "                \n",
    "        j,i,v = ss.find(self.U[user_i,:])\n",
    "        np.random.seed(42)\n",
    "        rand = np.random.uniform(size=j.size)\n",
    "        test_i = []\n",
    "        \n",
    "        x = 0\n",
    "        for jj,ii,r in zip(j,i,rand):\n",
    "            if r < test_size:\n",
    "                v[x] = 0\n",
    "                test_i.append((jj,ii))\n",
    "            x+=1\n",
    "                \n",
    "        #print(Uc)\n",
    "        #print(test_i)\n",
    "        \n",
    "        return j,i,v,test_i\n",
    "        \n",
    "\n",
    "        \n",
    "    def match_nodes(self,x,y):\n",
    "        if x['rating'] == y['rating']:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def ICA(self,user_i,verbose=True):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            - user_i: index of the user to perform ICA with\n",
    "        Returns:\n",
    "            - vector of predictions for user_i\n",
    "            - mae score of this vector\n",
    "        \"\"\"\n",
    "        import networkx as nx\n",
    "        import numpy as np\n",
    "        \n",
    "        j,i,v,test_i = self.train_test_split(user_i)\n",
    "        mean_rating = np.average(v)\n",
    "        G_ = self.G.copy()\n",
    "        \n",
    "        # Set initial ratings from the user. These include any testing points.\n",
    "        for x,ii in enumerate(i):\n",
    "            if v[x] != 0:\n",
    "                G_.nodes[self.ratings.index_to_title[ii]]['rating'] = v[x]\n",
    "                \n",
    "        # Initialize the rest of the nodes:\n",
    "        for n in G_.nodes():\n",
    "            if 'rating' not in G_.nodes[n]:\n",
    "                G_.nodes[n]['rating'] = 0\n",
    "\n",
    "                \n",
    "        # Start algorithm by initializing the nest time step and a time tracker.\n",
    "        G_plus = G_.copy()\n",
    "        num_zeros_ = -999\n",
    "        t = 0\n",
    "        still_changing = True\n",
    "        \n",
    "        \n",
    "        while still_changing:\n",
    "            if verbose:\n",
    "                print(f\"timestep: {t}\")\n",
    "            \n",
    "            # Recall that 'n' in this case is actually the title of the movie\n",
    "            for n in G_.nodes():\n",
    "                if G_.nodes[n]['rating'] == 0:\n",
    "                # To get the edges of each node, use G_[], to get the node props, use G_.nodes[]\n",
    "                    nns = G_[n]\n",
    "                    # Check each neighbor for ratings, and store them.\n",
    "                    nn_ratings = []\n",
    "                    nn_weights = []\n",
    "                    for nn in nns:\n",
    "                        if G_.nodes[nn]['rating'] != 0:\n",
    "                            nn_ratings.append(G_.nodes[nn]['rating'])\n",
    "                            nn_weights.append(G_[n][nn]['weight'])\n",
    "                    # If any ratings existed in the neighbors, update this node with the avg rating between neighbors.\n",
    "                    if nn_ratings:\n",
    "                        G_plus.nodes[n]['rating'] = np.average(nn_ratings,weights=nn_weights)\n",
    "\n",
    "            # Check if the graph is still changing:\n",
    "            ratings_list = list(nx.get_node_attributes(G_plus,'rating').values())\n",
    "            num_zeros_plus = ratings_list.count(0.0)\n",
    "            if verbose:\n",
    "                print(f\"number of zeroes remaining: {num_zeros_plus}\")\n",
    "            if num_zeros_plus == num_zeros_:\n",
    "                still_changing = False\n",
    "            \n",
    "            # Update pparameters for next iteration.\n",
    "            t+=1\n",
    "            num_zeros_ = num_zeros_plus\n",
    "            G_ = G_plus.copy()\n",
    "            \n",
    "        # END ITERATION\n",
    "        \n",
    "        # Fill in all remaining zeros with the average rating from this user\n",
    "        # and convert them back into a vector.\n",
    "        outvec = np.zeros(self.U.shape[1])\n",
    "        for n in G_.nodes():\n",
    "            if G_.nodes[n]['rating'] == 0:\n",
    "                G_.nodes[n]['rating'] = mean_rating\n",
    "            outvec[self.ratings.title_to_index[n]] = G_.nodes[n]['rating']\n",
    "            \n",
    "        # Finally, compute MAE if there are any test_i\n",
    "        if test_i:\n",
    "            err = []\n",
    "            for indices in test_i:\n",
    "                #print(indices)\n",
    "                #print(self.U[user_i,indices[1]], outvec[indices[1]])\n",
    "                err.append(self.U[user_i,indices[1]] - outvec[indices[1]])\n",
    "                #print(self.U[indices[0],indices[1]],outvec[indices[1]],err)\n",
    "            mae = np.sum(np.abs(np.array(err)))/len(test_i)\n",
    "            \n",
    "        else:\n",
    "            mae = np.nan\n",
    "                    \n",
    "            \n",
    "        return outvec, mae\n",
    "    \n",
    "    \n",
    "    def Absorb(self,user_i,verbose=True):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            - user_i: index of the user to perform ICA with\n",
    "        Returns:\n",
    "            - vector of predictions for user_i\n",
    "            - mae score of this vector\n",
    "        \"\"\"\n",
    "        import networkx as nx\n",
    "        import numpy as np\n",
    "        import random\n",
    "        \n",
    "        \n",
    "        j,i,v,test_i = self.train_test_split(user_i)\n",
    "        mean_rating = np.average(v)\n",
    "        G_ = self.G.copy()\n",
    "        \n",
    "        for x,ii in enumerate(i):\n",
    "            if v[x] != 0:\n",
    "                G_.nodes[self.ratings.index_to_title[ii]]['rating'] = v[x]\n",
    "        \n",
    "        for n in G_.nodes():\n",
    "            if 'rating' not in G_.nodes[n]:\n",
    "                G_.nodes[n]['rating'] = 0\n",
    "        \n",
    "        G_plus = G_.copy()\n",
    "        num_zeros_ = -999\n",
    "        t = 0\n",
    "        still_changing = True\n",
    "        \n",
    "        while still_changing:\n",
    "            if verbose:\n",
    "                print(f\"timestep: {t}\")\n",
    "            \n",
    "            # Recall that 'n' in this case is actually the title of the movie\n",
    "            for n in G_.nodes():\n",
    "                #print(n)\n",
    "                #if the node is rated at 0 we want to perform the absorbing method\n",
    "                if G_.nodes[n]['rating'] == 0:\n",
    "                    \n",
    "                    absNodeRatings = []\n",
    "                    #we want to try this method 'ki' times for each node\n",
    "                    ki = 50\n",
    "                    for kii in range(ki):\n",
    "                        newN = n\n",
    "                        # To get the edges of each node, use G_[], to get the node props, use G_.nodes[]\n",
    "                        absorbedRatings = []\n",
    "                        still_looking = 0\n",
    "                        while True:\n",
    "                            nns = G_[newN]\n",
    "                            # Check each neighbor for ratings, and store them.\n",
    "                            neighbors = []\n",
    "                            #nns is the nodes that are connected to our current node\n",
    "                            for nn in nns:\n",
    "                                #what im doing here is getting the weight of the edge\n",
    "                                #then adding the node to a list 'weight' times\n",
    "                                #Doing this for each edge will make a list with nodes to travel to\n",
    "                                #with the proportion of the weight\n",
    "                                weight= G_[newN][nn]['weight']\n",
    "                                for i in range(weight):\n",
    "                                    neighbors.append(nn)\n",
    "                                    \n",
    "                            #was getting error if neighbors was empty\n",
    "                            if neighbors:\n",
    "                                randNode = random.choice(neighbors)\n",
    "                            else:\n",
    "                                absorbedRatings.append(mean_rating)\n",
    "                            if G_.nodes[randNode]['rating'] != 0:\n",
    "                                absorbedRatings.append(G_.nodes[nn]['rating'])\n",
    "                                break\n",
    "                            else:\n",
    "                                newN = randNode\n",
    "                                still_looking += 1\n",
    "\n",
    "                            if still_looking >= 10:\n",
    "                                absorbedRatings.append(mean_rating)\n",
    "                                break\n",
    "                    G_plus.nodes[n]['rating'] = np.mean(absorbedRatings)\n",
    "        \n",
    "            ratings_list = list(nx.get_node_attributes(G_plus,'rating').values())\n",
    "            num_zeros_plus = ratings_list.count(0.0)\n",
    "            if num_zeros_plus == num_zeros_:\n",
    "                still_changing = False\n",
    "                \n",
    "            t+=1\n",
    "            num_zeros_ = num_zeros_plus\n",
    "            G_ = G_plus.copy()\n",
    "            \n",
    "            \n",
    "        # END ITERATION\n",
    "        \n",
    "        # Fill in all remaining zeros with the average rating from this user\n",
    "        # and convert them back into a vector.\n",
    "        outvec = np.zeros(self.U.shape[1])\n",
    "        for n in G_.nodes():\n",
    "            if G_.nodes[n]['rating'] == 0:\n",
    "                G_.nodes[n]['rating'] = mean_rating\n",
    "            outvec[self.ratings.title_to_index[n]] = G_.nodes[n]['rating']\n",
    "            \n",
    "        if test_i:\n",
    "            err = []\n",
    "            for indices in test_i:\n",
    "                #print(indices)\n",
    "                #print(self.U[user_i,indices[1]], outvec[indices[1]])\n",
    "                err.append(self.U[user_i,indices[1]] - outvec[indices[1]])\n",
    "                #print(self.U[indices[0],indices[1]],outvec[indices[1]],err)\n",
    "            mae = np.sum(np.abs(np.array(err)))/len(test_i)\n",
    "            \n",
    "        else:\n",
    "            mae = np.nan\n",
    "        \n",
    "        return outvec, mae\n",
    "    \n",
    "    \n",
    "    def Hitting_time(self,user_i,verbose=True,max_steps=50.0,num_walkers=100,lowest_k=3):\n",
    "        \"\"\"\n",
    "        An implementation of hitting time, as calculated from \n",
    "        random walk. The random walk is limited to max_steps, and any\n",
    "        nodes that are not reached at least once in max_steps are assigned \n",
    "        a hitting time of max_steps. The average hitting time for each node is\n",
    "        then calculated based off of the lowest_k lowest hitting time already-\n",
    "        rated movies.\n",
    "        \n",
    "        This implementation starts from the test nodes. Random walkers then traverse\n",
    "        the graph, and update the hitting time of each labeled (i.e. rated) node as they \n",
    "        reach it. If the movie being tested is isolated and has no neighbors, then the\n",
    "        average user's rating is used instead.\n",
    "        \n",
    "        Users that have less than lowest_k test movies are ignored.\n",
    "        \n",
    "        Returns a tuple of test indices (from self.U), predictions, and residuals; and \n",
    "        then the MAE.\n",
    "        \"\"\"\n",
    "        import networkx as nx\n",
    "        import numpy as np\n",
    "        import random\n",
    "        \n",
    "        # First, get all of the defined and undefined nodes, and make ratings\n",
    "        # for each (if they are already defined, use those. Else, use 0 and calculate)\n",
    "        # If the rating is already defined, save it's node to be iterated through for \n",
    "        # the hitting time algo.\n",
    "        j,i,v,test_i = self.train_test_split(user_i)\n",
    "        mean_rating = np.average(v)\n",
    "        G_ = self.G.copy()\n",
    "        \n",
    "        if len(test_i) >= lowest_k:\n",
    "        \n",
    "            labeled_nodes = []\n",
    "\n",
    "            # Initialize the network ratings:\n",
    "\n",
    "            for x,ii in enumerate(i):\n",
    "                if v[x] != 0:\n",
    "                    G_.nodes[self.ratings.index_to_title[ii]]['rating'] = v[x]\n",
    "                    labeled_nodes.append(self.ratings.index_to_title[ii])\n",
    "\n",
    "            for n in G_.nodes():\n",
    "                if 'rating' not in G_.nodes[n]:\n",
    "                    G_.nodes[n]['rating'] = 0\n",
    "\n",
    "            # Initialize the data objects to capture the hitting time stats.\n",
    "\n",
    "            # First, make an array that will store all of the hitting times from each\n",
    "            # labeled node for each unlabeled node. This matrix will therefore be n_test nodes\n",
    "            # x n_labeled nodes.\n",
    "\n",
    "            test_nodes = [i[1] for i in test_i]\n",
    "            test_node_names = [self.ratings.index_to_title[i] for i in test_nodes]\n",
    "\n",
    "            # Make a mapping for the random walk arrays.\n",
    "            tnn_to_index = dict(zip(test_node_names,range(len(test_node_names))))\n",
    "            index_to_tnn = dict(zip(range(len(test_node_names)),test_node_names))\n",
    "            ln_to_index = dict(zip(labeled_nodes,range(len(labeled_nodes))))\n",
    "            index_to_ln = dict(zip(range(len(labeled_nodes)),labeled_nodes))\n",
    "\n",
    "            hitting_times_matrix = np.full((len(test_node_names),len(labeled_nodes)),max_steps)\n",
    "\n",
    "            # Now, make a dictionary that will have an entry for each of the unlabeled nodes.\n",
    "            # Each of these entries will have a list of hitting times from a single test node.\n",
    "            for k,tnn in enumerate(test_node_names[:]):\n",
    "                \n",
    "                # Keep track of just the walks spawning from this labeled node (ln)\n",
    "                hitting_times_from_tnn = np.full((len(labeled_nodes),num_walkers),max_steps)\n",
    "                \n",
    "                # Check to make sure that there exists a path out of this movie. If not,\n",
    "                # just return the inner matrix of all 0s.\n",
    "                if len(list(G.neighbors(tnn))) > 0:\n",
    "\n",
    "                    # Start looping over walkers, taking up to max_steps - worth of steps.\n",
    "                    # THIS WOULD BE IDEAL PLACE FOR PARALLELIZATION.\n",
    "                    for x in range(num_walkers)[:]:\n",
    "\n",
    "                        # DEBUG:\n",
    "                        path = []\n",
    "\n",
    "                        step_i = 1\n",
    "                        current_node = tnn\n",
    "\n",
    "                        while step_i < max_steps:\n",
    "                            #DEBUG:\n",
    "                            path.append(current_node)\n",
    "\n",
    "                            # Get the neighbors to go to and make a probability list to pull from\n",
    "                            # based off of their weight. Choose the next node.\n",
    "\n",
    "                            nodes = [n for n in G_[current_node]]\n",
    "                            weights = [G_[current_node][n]['weight'] for n in G_[current_node]]\n",
    "\n",
    "                            # Check to make sure that there exists a path out of this movie. If not,\n",
    "                            # just return the inner matrix of all 0s.\n",
    "                            try:\n",
    "                                next_node = random.choices(nodes,weights,k=1)[0]\n",
    "                            except Exception as e:\n",
    "                                print(current_node)\n",
    "                                print(e)\n",
    "                                print(nodes)\n",
    "                                print(weights)\n",
    "                                print(path)\n",
    "                                raise SystemExit()\n",
    "\n",
    "                            # Now, update the first hitting time if haven't already\n",
    "                            if current_node in labeled_nodes:\n",
    "                                if hitting_times_from_tnn[ln_to_index[current_node],x] == max_steps:\n",
    "                                    hitting_times_from_tnn[ln_to_index[current_node],x] = step_i\n",
    "\n",
    "                            # Update for next random step\n",
    "                            step_i += 1\n",
    "                            current_node = next_node\n",
    "                            \n",
    "                else: \n",
    "                    \n",
    "                    print(f\"{tnn} has no neighbors...skipping\")\n",
    "                    hitting_times_from_tnn.fill(0.0)\n",
    "\n",
    "                # Take the average of hitting time for each unlabeled node. Then, add this column \n",
    "                # vector to the hitting time matrix, which keeps track of the average hitting time\n",
    "                # for each unlabeled node from each labeled node.\n",
    "\n",
    "                #print(np.nonzero(hitting_times_from_ln==9)) # <- find indicies of nonzero\n",
    "                mean_hitting_times_from_tnn = np.mean(hitting_times_from_tnn,axis=1)\n",
    "                #print(mean_hitting_times_from_tnn)\n",
    "                hitting_times_matrix[tnn_to_index[tnn],:] = mean_hitting_times_from_tnn\n",
    "                #print(np.nonzero(hitting_times_matrix!=max_steps))\n",
    "                if verbose:\n",
    "                    if k % 20 == 0:\n",
    "                        print(f\"{k} / {len(test_node_names)}\")\n",
    "\n",
    "            # Now, make predictions on all of the unlabeled movies (we will only use the ones\n",
    "            # that we need for the mae testing here. We would need a more powerful machine and \n",
    "            # implemented parallelization to handle much more than that)\n",
    "            # print(hitting_times_matrix)\n",
    "\n",
    "            # get the movies from test_i\n",
    "            # test_movies = [ratings.index_to_title[m[1]] for m in test_i]\n",
    "            # now get the indices in the hitting time matrix for those movies\n",
    "            # test_ht_indices = [un_to_index[title] for title in test_movies]\n",
    "\n",
    "            # Get the predicted score as an average of the lowest_k smallest\n",
    "            # hitting times. Then, compare to the utility matrix truth.\n",
    "            predictions = []\n",
    "            residuals = []\n",
    "            for test_j in range(hitting_times_matrix.shape[0])[:]:\n",
    "                #movie = index_to_un[un_j]\n",
    "                #utility_i = ratings.title_to_index[movie]\n",
    "                #print(test_i[x][1]) <--this gets the index for the utility matrix\n",
    "                test_vector = hitting_times_matrix[test_j,:].squeeze()\n",
    "                \n",
    "                # Catch the movies with no neighbors, and simply predicted the average:\n",
    "                if np.sum(test_vector) < 0.0001:\n",
    "                    predicted_score = mean_rating\n",
    "                else:\n",
    "                    closest_hits = self.get_smallest_indices(test_vector,lowest_k)\n",
    "                    closest_hits_movies = [index_to_ln[i] for i in closest_hits]\n",
    "                    closest_hits_scores = np.array([G_.nodes[i]['rating'] for i in closest_hits_movies])\n",
    "                    predicted_score = np.mean(closest_hits_scores)\n",
    "                    \n",
    "                predictions.append(predicted_score)\n",
    "                residuals.append(self.U[user_i,test_i[test_j][1]]-predicted_score)\n",
    "            mae = np.mean(np.abs(residuals))\n",
    "\n",
    "            # Gather some other information\n",
    "            other = (test_i,predictions,residuals)\n",
    "        \n",
    "        else:\n",
    "            mae = np.nan\n",
    "            other = None\n",
    "\n",
    "        # return\n",
    "        return other,mae\n",
    "            \n",
    "                \n",
    "        \n",
    "    def get_smallest_indices(self,v,k):\n",
    "        \"\"\"\n",
    "        Returns the indices of the smallest k elements of 1d array v.\n",
    "        They are unsorted.\n",
    "        \"\"\"\n",
    "        return np.argpartition(v,k)[:k]\n",
    "            \n",
    "    \n",
    "    \n",
    "    def testing_algo(self,algorithm,number_of_users=100):\n",
    "        import random\n",
    "        import numpy as np\n",
    "        \n",
    "        users = list(range(self.U.shape[0]))\n",
    "        sample = random.sample(users,k=number_of_users)\n",
    "        \n",
    "        ms = []\n",
    "        if algorithm == 'ICA':\n",
    "            for x,j in enumerate(sample):\n",
    "                #print(x,j)\n",
    "                print(f\"Sample: {x}\")\n",
    "                o,m = self.ICA(j,verbose=False)\n",
    "                ms.append(m)\n",
    "\n",
    "            return np.nanmean(ms)\n",
    "        \n",
    "        if algorithm == 'Absorb':\n",
    "            for x,j in enumerate(sample):\n",
    "                #print(x,j)\n",
    "                print(f\"Sample: {x}\")\n",
    "                o,m = self.Absorb(j,verbose=False)\n",
    "                ms.append(m)\n",
    "\n",
    "            return np.nanmean(ms)\n",
    "        \n",
    "        if algorithm == 'HT':\n",
    "            for x,j in enumerate(sample):\n",
    "                #print(x,j)\n",
    "                print(f\"Sample: {x}\")\n",
    "                o,m = self.Hitting_time(j,verbose=True)\n",
    "                ms.append(m)\n",
    "\n",
    "            return np.nanmean(ms)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = util.parse_nodes_edge_file('AllActorG.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 45\n",
      "1 / 45\n",
      "2 / 45\n",
      "3 / 45\n",
      "4 / 45\n",
      "5 / 45\n",
      "6 / 45\n",
      "7 / 45\n",
      "8 / 45\n",
      "9 / 45\n",
      "10 / 45\n",
      "11 / 45\n",
      "12 / 45\n",
      "13 / 45\n",
      "14 / 45\n",
      "15 / 45\n",
      "16 / 45\n",
      "17 / 45\n",
      "18 / 45\n",
      "19 / 45\n",
      "20 / 45\n",
      "21 / 45\n",
      "22 / 45\n",
      "23 / 45\n",
      "24 / 45\n",
      "25 / 45\n",
      "26 / 45\n",
      "27 / 45\n",
      "28 / 45\n",
      "29 / 45\n",
      "30 / 45\n",
      "31 / 45\n",
      "32 / 45\n",
      "33 / 45\n",
      "34 / 45\n",
      "35 / 45\n",
      "36 / 45\n",
      "37 / 45\n",
      "38 / 45\n",
      "39 / 45\n",
      "40 / 45\n",
      "41 / 45\n",
      "42 / 45\n",
      "43 / 45\n",
      "44 / 45\n",
      "0.6740740740740742\n"
     ]
    }
   ],
   "source": [
    "network = Network_Recommender(G,ratings)\n",
    "network.Hitting_time(4,num_walkers=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n",
      "0 / 11\n",
      "Sample: 1\n",
      "0 / 37\n",
      "20 / 37\n",
      "Sample: 2\n",
      "0 / 18\n",
      "Sample: 3\n",
      "0 / 60\n",
      "20 / 60\n",
      "40 / 60\n",
      "Sample: 4\n",
      "Sample: 5\n",
      "0 / 6\n",
      "Sample: 6\n",
      "0 / 95\n",
      "20 / 95\n",
      "40 / 95\n",
      "60 / 95\n",
      "80 / 95\n",
      "Sample: 7\n",
      "0 / 13\n",
      "Sample: 8\n",
      "0 / 6\n",
      "Sample: 9\n",
      "0 / 7\n",
      "0.7055252499696942\n"
     ]
    }
   ],
   "source": [
    "G = util.parse_nodes_edge_file('AllActorG.net')\n",
    "network = Network_Recommender(G,ratings)\n",
    "#print(network.testing_algo(algorithm='ICA', number_of_users=100))\n",
    "#print(network.testing_algo(algorithm='Absorb', number_of_users=100))\n",
    "print(network.testing_algo(algorithm='HT', number_of_users=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
